Resources
Read or watch:

An Introduction to Word Embeddings
Introduction to Word Embeddings
Natural Language Processing|Bag Of Words Intuition
Natural Language Processing|TF-IDF Intuition| Text Prerocessing
Word Embedding - Natural Language Processing| Deep Learning
Word2Vec Tutorial - The Skip-Gram Model
Word2Vec Tutorial Part 2 - Negative Sampling
GloVe Explained
FastText: Under the Hood
ELMo Explained
Definitions to skim

Natural Language Processing
References:

Efficient Estimation of Word Representations in Vector Space (Skip-gram, 2013)
Distributed Representations of Words and Phrases and their Compositionality (Word2Vec, 2013)
GloVe: Global Vectors for Word Representation (website)
GloVe: Global Vectors for Word Representation (2014)
fastText (website)
Bag of Tricks for Efficient Text Classification (fastText, 2016)
Enriching Word Vectors with Subword Information (fastText, 2017)
Probabilistic FastText for Multi-Sense Word Embeddings (2018)
ELMo (website)
Deep contextualized word representations (ELMo, 2018)
sklearn.feature_extraction.text.CountVectorizer
sklearn.feature_extraction.text.TfidfVectorizer
genism.models.word2vec
genism.models.fasttext
